{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created on 11/25/15 (last day at clarapath; just had dinner w momo and dodo - beef noodle soup)\n",
    "\n",
    "updated on 11/28/15 (bay will arrive at jfk in 3 hours from taiwan) \n",
    "\n",
    "updated on 12/11/15 (month off before samsung; will have pair programming at triplelift; work at ace hotel with al later today; updating this as im reviewing manifold learning, which discusses representation learning in NLP).\n",
    "\n",
    "updated on 12/28/15 (week before sams; at brazilia coffeeshop; just including notes).\n",
    "\n",
    "word2vec is word embedding. the assumption is that there are only 300-500 topics that are represented in high dimensional space (100,000+ words in a vocabulary). therefore, the goal is to re-map topics that are represented in natural langauge (high D) back to topics (low D). by doing so, you are learning the manifold upon which topics reside.\n",
    "\n",
    "\n",
    "\n",
    "data source: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE # works better than the tsne package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each review is split into a list of tokens; text is a list of lists\n",
    "\n",
    "text = unlabeled_train['review'].map(lambda x: x.lower().split())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: train word2vec model\n",
    "\n",
    "alternatively, there is a pretrained glove model here: http://aylien.com/web-summit-2015-tweets-part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "execution time:  49.4065539837\n"
     ]
    }
   ],
   "source": [
    "print \"training...\"\n",
    "\n",
    "# ~1 min to train\n",
    "# min count is minimum frequency of words in order to be relevant\n",
    "# size is the size of feature vector, usually between 50 and 300\n",
    "# workers = number of cores\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "model = gensim.models.Word2Vec(text, size=100, window=5, min_count=10, workers=4)\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print 'execution time: ', elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# persist trained word2vec model\n",
    "\n",
    "model.save('word2vec_bagofpopcorn_112515.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8233506679534912),\n",
       " ('guy', 0.7667827010154724),\n",
       " ('girl', 0.7538588047027588),\n",
       " ('doctor', 0.7214196920394897),\n",
       " ('soldier', 0.7119728326797485),\n",
       " ('kid', 0.6974995136260986),\n",
       " ('lad', 0.6902358531951904),\n",
       " ('boy', 0.6861493587493896),\n",
       " ('lady', 0.6630043983459473),\n",
       " ('man,', 0.6591916084289551)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect word similarities\n",
    "\n",
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82335055]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similiarity is cosine - lets verify\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(model['man'], model['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43962"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of model's vocabulary is 44k\n",
    "\n",
    "len(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each word in the vocabulary has 100 dimensions\n",
    "\n",
    "model.syn0[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analogies!\n",
    "\n",
    "reference: http://arxiv.org/pdf/1301.3781v3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man = model['man']\n",
    "boy = model['boy']\n",
    "girl = model['girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown = man - boy + girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "woman = model['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8172642]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(unknown, woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: generate word representations\n",
    "\n",
    "These representations, hopefully, make the data “nicer” for the network to classify. There has been a lot of work exploring representations recently. Perhaps the most fascinating has been in Natural Language Processing: the representations we learn of words, called word embeddings, have interesting properties.\n",
    "\n",
    "reference: https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_class0 = ['plane', 'ship', 'boat', 'bus', 'truck', 'bridge', 'car', 'helicopter',\n",
    "               'spaceship', 'train', 'flight', 'ferry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_class1 = ['aliens', 'robots', 'zombies', 'spiders', 'vampires', 'mummies', 'gangsters',\n",
    "                'bees', 'monsters', 'wasps', 'creatures', 'predators', 'animals', 'poachers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = words_class0 + words_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0] * len(words_class0) + [1] * len(words_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe where rows = words; columns = concepts\n",
    "\n",
    "x_df = []\n",
    "\n",
    "for word in words:\n",
    "    x_df.append(model[word])\n",
    "    \n",
    "x_df = pd.DataFrame(np.vstack(x_df))\n",
    "\n",
    "x_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: visualize word representations\n",
    "\n",
    "updated on 11/28/15 (bay will arrive at jfk in 3 hours from taiwan) to include 2-step dimensionality technique of svd + tsne. \n",
    "\n",
    "the technique sues svd to reduce high dimensions to something lower, and then applying t-sne to further reduction.\n",
    "\n",
    "http://aylien.com/web-summit-2015-tweets-part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=10, random_state=0)\n",
    "x_df_svd = svd.fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 26 / 26\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] Error after 65 iterations with early exaggeration: 8.297118\n",
      "[t-SNE] Error after 285 iterations: 0.516343\n"
     ]
    }
   ],
   "source": [
    "x = TSNE(n_components=2, perplexity=40, learning_rate=100, verbose=1).fit_transform(x_df_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x138db7c10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1389da9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "split_pt = len(words_class0) # split points in order to better visualize data\n",
    "\n",
    "plt.scatter(x[:split_pt, 0], x[:split_pt, 1], c = 'r', marker = 's')\n",
    "plt.scatter(x[split_pt:, 0], x[split_pt:, 1], c = 'b', marker = 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: generate clusters\n",
    "\n",
    "lets create clusters of semantically related words that share the same concept.\n",
    "\n",
    "this is effectively LDA analysis. in LDA, you return a bunch of topics, each represented by a high dimensional vector of words. in word2vec, you return a bunch of words, each represented by a high dimensional vector of topics. so, LDA is the same as word2vec!\n",
    "\n",
    "by clustering into semantically related clusters, you are transforming word2vec to LDA.\n",
    "\n",
    "updated 11/28/15 to use minibatch kmeans. minibatch kmeans processes samples in batches rather individually and is therefore faster. reference: http://aylien.com/web-summit-2015-tweets-part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_clusters = 5000\n",
    "\n",
    "# kmeans = KMeans(n_clusters = num_clusters)\n",
    "kmeans = MiniBatchKMeans(n_clusters = num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit kmeans on 5k out of 44k\n",
    "\n",
    "training_data = model.syn0[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:1273: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "        init_size=None, max_iter=100, max_no_improvement=10,\n",
       "        n_clusters=5000, n_init=3, random_state=None,\n",
       "        reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate dict where k = centroid label and v = list of similar words\n",
    "\n",
    "clusters_dict = {}\n",
    "\n",
    "for i in range(0, num_clusters):\n",
    "    clusters_dict[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each word in the vocabulary\n",
    "for i, w in enumerate(model.syn0):\n",
    "    \n",
    "    # assign word vector to a cluster\n",
    "    k = kmeans.predict(w)[0]\n",
    "    \n",
    "    # find corresponding word to the word vector\n",
    "    word = model.index2word[i] # index2word is a gensim method\n",
    "    \n",
    "    # then add corresponding word to the dictionary where k = centroid label and v = list of words\n",
    "    clusters_dict[k].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ['comments']\n",
      "151 [\"wouldn't\"]\n",
      "152 ['supposed']\n",
      "153 ['(brazil):']\n",
      "154 ['scares', 'shocks', 'scares,', 'surprises.', 'thrills,']\n",
      "155 ['then']\n",
      "156 ['enjoyable.', 'disappointing.', 'good.\"', 'sad.', 'watchable.', 'entertaining.\"']\n",
      "157 ['dollars']\n",
      "158 ['does']\n",
      "159 ['teeth', 'butt', 'brains', 'shaking', 'knocking', 'ears', 'jaw', 'skin.', 'socks', 'toes', 'eyeballs']\n"
     ]
    }
   ],
   "source": [
    "# inspect clusters of concepts!\n",
    "\n",
    "for idx in range(150, 160):\n",
    "    print idx, clusters_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
