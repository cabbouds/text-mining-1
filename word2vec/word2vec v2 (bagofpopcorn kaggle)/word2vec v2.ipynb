{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created on 11/25/15 (last day at clarapath; just had dinner w momo and dodo)\n",
    "\n",
    "data source: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE # works better than the tsne package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each review is split into a list of tokens; text is a list of lists\n",
    "\n",
    "text = unlabeled_train['review'].map(lambda x: x.lower().split())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "execution time:  48.897685051\n"
     ]
    }
   ],
   "source": [
    "print \"training...\"\n",
    "\n",
    "# ~1 min to train\n",
    "# min count is minimum frequency of words in order to be relevant\n",
    "# size is the size of feature vector, usually between 50 and 300\n",
    "# workers = number of cores\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "model = gensim.models.Word2Vec(text, size=100, window=5, min_count=10, workers=4)\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print 'execution time: ', elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# persist trained word2vec model\n",
    "\n",
    "model.save('word2vec_bagofpopcorn_112515.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8108645677566528),\n",
       " ('girl', 0.7665234804153442),\n",
       " ('man,', 0.7512650489807129),\n",
       " ('guy', 0.7348310947418213),\n",
       " ('soldier', 0.7087733745574951),\n",
       " ('boy', 0.6984727382659912),\n",
       " ('lady', 0.6977645754814148),\n",
       " ('lad', 0.6935749650001526),\n",
       " ('kid', 0.6687204241752625),\n",
       " ('person', 0.6583636999130249)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect word similarities\n",
    "\n",
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69847274]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similiarity is cosine - lets verify\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(man, boy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43962"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of model's vocabulary is 44k\n",
    "\n",
    "len(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each word in the vocabulary has 100 dimensions\n",
    "\n",
    "model.syn0[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analogies!\n",
    "\n",
    "reference: http://arxiv.org/pdf/1301.3781v3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man = model['man']\n",
    "boy = model['boy']\n",
    "girl = model['girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown = man - boy + girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "woman = model['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8395465]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(unknown, woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: generate word representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_class0 = ['plane', 'ship', 'boat', 'bus', 'truck', 'bridge', 'car', 'helicopter',\n",
    "               'spaceship', 'train', 'flight', 'ferry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_class1 = ['aliens', 'robots', 'zombies', 'spiders', 'vampires', 'mummies', 'gangsters',\n",
    "                'bees', 'monsters', 'wasps', 'creatures', 'predators', 'animals', 'poachers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = words_class0 + words_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0] * len(words_class0) + [1] * len(words_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe where rows = words; columns = concepts\n",
    "\n",
    "x_df = []\n",
    "\n",
    "for word in words:\n",
    "    x_df.append(model[word])\n",
    "    \n",
    "x_df = pd.DataFrame(np.vstack(x_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: visualize word representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 26 / 26\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] Error after 67 iterations with early exaggeration: 8.014977\n",
      "[t-SNE] Error after 279 iterations: 0.492153\n"
     ]
    }
   ],
   "source": [
    "x = TSNE(n_components=2, perplexity=40, learning_rate=100, verbose=1).fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13670cc90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenttang/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137ac3590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "split_pt = len(words_class0) # split points in order to better visualize data\n",
    "\n",
    "plt.scatter(x[:split_pt, 0], x[:split_pt, 1], c = 'r', marker = 's')\n",
    "plt.scatter(x[split_pt:, 0], x[split_pt:, 1], c = 'b', marker = 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5: generate clusters\n",
    "\n",
    "lets create clusters of semantically related words that share the same concept.\n",
    "\n",
    "this is effectively LDA analysis. in LDA, you return a bunch of topics, each represented by a high dimensional vector of words. in word2vec, you return a bunch of words, each represented by a high dimensional vector of topics. so, LDA is the same as word2vec!\n",
    "\n",
    "by clustering into semantically related clusters, you are transforming word2vec to LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5000\n",
    "\n",
    "kmeans = KMeans(n_clusters = num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit kmeans on 5k out of 44k\n",
    "\n",
    "training_data = model.syn0[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=5000,\n",
       "    n_init=10, n_jobs=1, precompute_distances='auto', random_state=None,\n",
       "    tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate dict where k = centroid label and v = list of similar words\n",
    "\n",
    "clusters_dict = {}\n",
    "\n",
    "for i in range(0, num_clusters):\n",
    "    clusters_dict[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each word in the vocabulary\n",
    "for i, w in enumerate(model.syn0):\n",
    "    \n",
    "    # assign word vector to a cluster\n",
    "    k = kmeans.predict(w)[0]\n",
    "    \n",
    "    # find corresponding word to the word vector\n",
    "    word = model.index2word[i] # index2word is a gensim method\n",
    "    \n",
    "    # then add corresponding word to the dictionary where k = centroid label and v = list of words\n",
    "    clusters_dict[k].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['u']\n",
      "51 ['twenty']\n",
      "52 ['7']\n",
      "53 ['disaster']\n",
      "54 ['have.', '\"how', 'dismiss', 'imagine.']\n",
      "55 ['spending']\n",
      "56 ['instance,']\n",
      "57 ['describes', 'relates', 'dominates']\n",
      "58 ['teeth', 'brains', 'ears', 'jaw', 'scratching', 'mates', 'toes']\n",
      "59 ['budget,']\n"
     ]
    }
   ],
   "source": [
    "# inspect clusters of concepts!\n",
    "\n",
    "for idx in range(50, 60):\n",
    "    print idx, clusters_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
